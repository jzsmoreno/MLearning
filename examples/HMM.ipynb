{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. **Modelo de Cadenas de Markov Ocultas (HMM)**\n",
    "\n",
    "Un **Modelo de Cadena de Markov Oculta (HMM, por sus siglas en inglés)** es una técnica estocástica que se utiliza para modelar procesos generadores de cadenas de observaciones aleatorias y que incluyen elementos ocultos que no se pueden observar directamente. El objetivo del modelo es inferir los estados ocultos a partir de las observaciones disponibles.\n",
    "\n",
    "### Componentes Fundamentales\n",
    "\n",
    "Un HMM tiene tres componentes fundamentales: $\\pi$, $A$ y $B$. Estos son los parámetros que permiten modelar el comportamiento del sistema, y cómo se pueden generar las observaciones a partir de los estados ocultos. A continuación se explica cada uno:\n",
    "\n",
    "1. **$\\pi$ (Distribución inicial)**: Es un vector que describe la probabilidad inicial de que el sistema se encuentre en cada uno de los posibles states ocultos al comienzo del proceso. $\\pi$ establece cómo se distribuyen las probabilidades de los states en el tiempo inicial $t=0$.\n",
    "\n",
    "2. **$A$ (Matriz de transición)**: Es una tabla que describe las probabilidades de transición entre los states ocultos. Se utiliza para modelar cómo un estado oculto puede pasar a otro en el siguiente paso temporal del proceso.\n",
    "\n",
    "3. **$B$ (Matriz de emisión)**: Es otra tabla que describe las probabilidades de emisión de observaciones específicas. Estas son las posibles observaciones que podemos esperar ver dadas determinados states ocultos y transiciones entre ellos.\n",
    "\n",
    "### Ejemplo\n",
    "\n",
    "Imagine que quieres modelar un proceso en el que un paciente puede estar en uno de tres states ocultos: \"Resfriado\", \"Gripe\" o \"COVID-19\". Al inicio del proceso, el estado del paciente es aleatorio (por ejemplo, con una probabilidad igual de 1/3 para cada uno). Luego, en cada paso temporal, el paciente puede pasar a otro estado con ciertas probabilidades determinadas. Finalmente, hay posibles observaciones que podemos esperar ver: tos, fiebre y dolor de garganta.\n",
    "\n",
    "### Cálculo de $\\alpha_t(i)$\n",
    "\n",
    "El algoritmo de **Forward** calcula la probabilidad $\\alpha_t(i)$ de estar en el estado $i$ en un tiempo temporal dado $t$, cuando hemos observado una secuencia de observaciones hasta ese punto. El cálculo se realiza de manera recursiva utilizando las probabilidades iniciales, la transición y emisión.\n",
    "\n",
    "### Ejemplo\n",
    "\n",
    "Supongamos que queremos encontrar $\\alpha_2(2)$, es decir, la probabilidad de estar en el estado \"COVID-19\" en el segundo paso temporal ($t=2$), cuando hemos observado una secuencia de observaciones $O=[o_1, o_2]$ hasta ese momento.\n",
    "\n",
    "Para este cálculo, se necesita la distribución inicial $\\pi$, la transición $A$ y la emisión $B$. Por ejemplo:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\pi = [0.5, 0.3, 0.2] \\\\\n",
    "A = \\begin{bmatrix}\n",
    "0.7 & 0.2 & 0.1 \\\\\n",
    "0.3 & 0.4 & 0.3 \\\\\n",
    "0.2 & 0.3 & 0.5\n",
    "\\end{bmatrix} \\\\\n",
    "B = \\begin{bmatrix}\n",
    "0.4 & 0.4 & 0.2 \\\\\n",
    "0.5 & 0.3 & 0.2 \\\\\n",
    "0.3 & 0.5 & 0.2\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Entonces, para calcular $\\alpha_2(2)$, podemos seguir los siguientes pasos:\n",
    "\n",
    "1. En el primer tiempo ($t=0$), la probabilidad de estar en cada estado es igual a $\\pi$, por lo que:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\alpha_0(1) &= 0.5 \\\\\n",
    "\\alpha_0(2) &= 0.3 \\\\\n",
    "\\alpha_0(3) &= 0.2 \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "2. En el segundo tiempo ($t=1$), las probabilidades de estar en cada estado se calculan utilizando $\\alpha_0(i)$ y $A$. Por ejemplo:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\alpha_1(1) &= 0.7 \\cdot 0.5 + 0.2 \\cdot 0.3 + 0.1 \\cdot 0.2 = 0.43 \\\\\n",
    "\\alpha_1(2) &= 0.3 \\cdot 0.5 + 0.4 \\cdot 0.3 + 0.3 \\cdot 0.2 = 0.33 \\\\\n",
    "\\alpha_1(3) &= 0.2 \\cdot 0.5 + 0.3 \\cdot 0.3 + 0.5 \\cdot 0.2 = 0.29\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "3. En el tercer tiempo ($t=2$), las probabilidades de estar en cada estado se calculan utilizando $\\alpha_1(i)$ y $A$. Por ejemplo:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\alpha_2(1) &= 0.7 \\cdot 0.43 + 0.2 \\cdot 0.33 + 0.1 \\cdot 0.29 = 0.39 \\\\\n",
    "\\alpha_2(2) &= 0.3 \\cdot 0.43 + 0.4 \\cdot 0.33 + 0.3 \\cdot 0.29 = 0.33 \\\\\n",
    "\\alpha_2(3) &= 0.2 \\cdot 0.43 + 0.3 \\cdot 0.33 + 0.5 \\cdot 0.29 = 0.33\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Entonces, $\\alpha_2(2)$ es la probabilidad de estar en el estado \"COVID-19\" en el tercer tiempo, dado las observaciones hasta ese punto y los parámetros del modelo HMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Add the parent directory to the system path to allow importing from modules located there\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "# Import necessary libraries\n",
    "from likelihood.models.hmm import HMM\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration: (3, 2, 50) with accuracy 80.00%\n",
      "Pi:  [0.30679364 0.46013642 0.23306995]\n",
      "A:\n",
      " [[7.45886071e-01 2.12238093e-01 4.18758355e-02]\n",
      " [4.30721149e-06 3.99281773e-09 9.99995689e-01]\n",
      " [4.56136090e-06 9.99995431e-01 7.95169145e-09]]\n",
      "B:\n",
      " [[0.52814729 0.47185271]\n",
      " [0.45275598 0.54724402]\n",
      " [0.62723495 0.37276505]]\n"
     ]
    }
   ],
   "source": [
    "# Define the HMM class (the one we just created)\n",
    "# If you haven't already, make sure to define the HMM class with the methods we discussed.\n",
    "\n",
    "# Define the parameters of the model\n",
    "n_states = 3  # Sunny (0), Rainy (1), Cloudy (2)\n",
    "n_observations = 2  # Walk (0), Shop (1)\n",
    "\n",
    "# Create an HMM instance\n",
    "hmm = HMM(n_states, n_observations)\n",
    "\n",
    "# Generate some synthetic observation sequences (e.g., 3 sequences of 5 days)\n",
    "# Each number represents an observation: 0 -> Walk, 1 -> Shop\n",
    "sequences = [\n",
    "    [0, 1, 0, 0, 1],  # Sequence 1: Walk, Shop, Walk, Walk, Shop\n",
    "    [1, 1, 0, 1, 0],  # Sequence 2: Shop, Shop, Walk, Shop, Walk\n",
    "    [0, 0, 0, 1, 1],  # Sequence 3: Walk, Walk, Walk, Shop, Shop\n",
    "]\n",
    "\n",
    "# Define the true hidden states for the sequences (ground truth for training/testing)\n",
    "true_states = [\n",
    "    [0, 0, 0, 1, 2],  # Sequence 1: Sunny, Sunny, Sunny, Rainy, Cloudy\n",
    "    [1, 1, 0, 1, 2],  # Sequence 2: Rainy, Rainy, Sunny, Rainy, Cloudy\n",
    "    [0, 0, 0, 1, 2],  # Sequence 3: Sunny, Sunny, Sunny, Rainy, Cloudy\n",
    "]\n",
    "\n",
    "# Test various model configurations\n",
    "iterations_configs = [20, 50, 100, 200]\n",
    "best_accuracy = 0\n",
    "best_config = None\n",
    "\n",
    "for n_iter in iterations_configs:\n",
    "    hmm = HMM(n_states, n_observations)\n",
    "    hmm.baum_welch(sequences, n_iterations=n_iter)\n",
    "    accuracy = hmm.decoding_accuracy(sequences, true_states)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_config = (n_states, n_observations, n_iter)\n",
    "        hmm.save_model()\n",
    "\n",
    "print(f\"Best configuration: {best_config} with accuracy {best_accuracy:.2f}%\")\n",
    "print(\"Pi: \", hmm.pi)\n",
    "print(\"A:\\n\", hmm.A)\n",
    "print(\"B:\\n\", hmm.B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding Accuracy (model rebuilt): 80.00%\n",
      "Test Sequence: [0, 1, 0, 0, 1]\n",
      "Predicted States: [0 1 0 1 2]\n",
      "Probabilities of hidden states: [[0.31948497 0.37924309 0.30127194]\n",
      " [0.4722999  0.23295822 0.29474188]\n",
      " [0.48456782 0.22259576 0.29283641]\n",
      " [0.44177606 0.25941242 0.29881152]\n",
      " [0.42705946 0.31086997 0.26207056]]\n",
      "Total probability: [0.42705946 0.31086997 0.26207056]\n"
     ]
    }
   ],
   "source": [
    "hmm = HMM(n_states, n_observations)\n",
    "hmm = hmm.load_model()\n",
    "accuracy = hmm.decoding_accuracy(sequences, true_states)\n",
    "print(f\"Decoding Accuracy (model rebuilt): {accuracy:.2f}%\")\n",
    "test_sequence = [0, 1, 0, 0, 1]  # Test sequence: Walk, Shop, Walk, Walk, Shop\n",
    "predicted_states = hmm.viterbi(test_sequence)\n",
    "smoothed_probs = hmm.state_probabilities(test_sequence)\n",
    "total_prob = hmm.sequence_probability(test_sequence)\n",
    "\n",
    "print(f\"Test Sequence: {test_sequence}\")\n",
    "print(f\"Predicted States: {predicted_states}\")\n",
    "print(f\"Probabilities of hidden states: {smoothed_probs}\")\n",
    "print(f\"Total probability: {total_prob}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
