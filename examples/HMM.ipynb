{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos Ocultos de Markov (HMM)\n",
    "\n",
    "En un **Modelo de Cadenas de Markov Ocultas (HMM, por sus siglas en inglés)**, los parámetros fundamentales son **π**, **A** y **B**. Estos son los componentes esenciales que permiten definir completamente el comportamiento del modelo, y cómo se pueden generar las observaciones a partir de los estados ocultos. A continuación, se explica cada uno de estos parámetros:\n",
    "\n",
    "## 1. **π (Distribución inicial de los estados)**\n",
    "\n",
    "**π** es un **vector** que describe la **probabilidad inicial** de que el sistema se encuentre en cada uno de los posibles estados ocultos al comienzo del proceso. En otras palabras, π establece cómo se distribuyen las probabilidades de los estados en el tiempo inicial $ t = 0 $.\n",
    "\n",
    "### Formalmente:\n",
    "Si $( S_1, S_2, \\dots, S_N )$ son los estados ocultos, entonces $ \\pi_i $ es la probabilidad de que el sistema comience en el estado $ i $ al inicio (en $ t = 0 $).\n",
    "\n",
    "### Propiedad:\n",
    "La suma de todas las probabilidades de $ \\pi $ debe ser igual a 1:\n",
    "$$\n",
    "\\sum_{i=1}^N \\pi_i = 1\n",
    "$$\n",
    "Es decir, la probabilidad de que el sistema comience en algún estado oculto debe ser 100%.\n",
    "\n",
    "### Ejemplo:\n",
    "Imagina que tienes tres posibles estados ocultos, como en el caso de un diagnóstico médico: \"Resfriado\", \"Gripe\" y \"COVID-19\". La distribución inicial $ \\pi $ podría ser:\n",
    "$$\n",
    "\\pi = \\left[ 0.5, 0.3, 0.2 \\right]\n",
    "$$\n",
    "Esto significa que:\n",
    "- Hay un 50% de probabilidad de que el sistema comience en el estado \"Resfriado\".\n",
    "- Hay un 30% de probabilidad de que el sistema comience en el estado \"Gripe\".\n",
    "- Hay un 20% de probabilidad de que el sistema comience en el estado \"COVID-19\".\n",
    "\n",
    "## 2. **A (Matriz de transición de los estados)**\n",
    "\n",
    "**A** es una **matriz de transición** que describe las **probabilidades de transición** entre los estados ocultos. Es decir, define las probabilidades de pasar de un estado oculto a otro en el siguiente paso temporal del proceso.\n",
    "\n",
    "### Formalmente:\n",
    "$ A_{ij} $ es la probabilidad de transitar del estado oculto $ S_i $ al estado oculto $ S_j $. Cada fila $ i $-ésima de la matriz $ A $ describe cómo el sistema transita desde el estado $ S_i $ hacia cualquier otro estado en el siguiente paso.\n",
    "\n",
    "### Propiedad:\n",
    "Cada fila de la matriz $ A $ debe ser una distribución de probabilidad, es decir:\n",
    "$$\n",
    "\\sum_{j=1}^N A_{ij} = 1\n",
    "$$\n",
    "Esto significa que las probabilidades de transición desde cualquier estado $ S_i $ hacia otros estados deben sumar 1.\n",
    "\n",
    "### Ejemplo:\n",
    "Si tienes tres estados ocultos y la matriz de transición $ A $ es la siguiente:\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "0.7 & 0.2 & 0.1 \\\\\n",
    "0.3 & 0.4 & 0.3 \\\\\n",
    "0.2 & 0.3 & 0.5\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Esto indica que:\n",
    "- Si el sistema está en el estado \"Resfriado\" en un momento dado, tiene un 70% de probabilidad de permanecer en el estado \"Resfriado\" en el siguiente paso, un 20% de pasar al estado \"Gripe\" y un 10% de pasar al estado \"COVID-19\".\n",
    "- Similarmente, las transiciones entre \"Gripe\" y \"COVID-19\" tienen sus respectivas probabilidades de ocurrir.\n",
    "\n",
    "## 3. **B (Matriz de emisión de observaciones)**\n",
    "\n",
    "**B** es una **matriz de emisión** que describe las **probabilidades de emisión de observaciones**. Es decir, la probabilidad de observar un evento dado un estado oculto específico. En otras palabras, **B** determina la probabilidad de que un estado oculto genere una observación particular.\n",
    "\n",
    "### Formalmente:\n",
    "$ B_{ij} $ es la probabilidad de observar la salida $ O_j $ dado que el sistema se encuentra en el estado oculto $ S_i $. Esto indica cómo un estado oculto $ S_i $ genera las observaciones posibles $( O_1, O_2, ..., O_M )$.\n",
    "\n",
    "### Propiedad:\n",
    "Al igual que en $ A $, cada fila de la matriz $ B $ debe ser una distribución de probabilidad, es decir:\n",
    "$$\n",
    "\\sum_{j=1}^M B_{ij} = 1\n",
    "$$\n",
    "donde $ M $ es el número de posibles observaciones.\n",
    "\n",
    "### Ejemplo:\n",
    "Imagina que tenemos 3 estados ocultos (\"Resfriado\", \"Gripe\", \"COVID-19\") y 3 posibles observaciones (\"tos\", \"fiebre\", \"dolor de garganta\"). Una posible matriz de emisión $ B $ podría ser:\n",
    "$$\n",
    "B = \\begin{bmatrix}\n",
    "0.4 & 0.4 & 0.2 \\\\\n",
    "0.5 & 0.3 & 0.2 \\\\\n",
    "0.3 & 0.5 & 0.2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Esto indica que:\n",
    "- Si el sistema está en el estado \"Resfriado\", tiene un 40% de probabilidad de observar \"tos\", un 40% de observar \"fiebre\" y un 20% de observar \"dolor de garganta\".\n",
    "- Si está en \"Gripe\", tiene un 50% de probabilidad de observar \"tos\", un 30% de observar \"fiebre\", y un 20% de observar \"dolor de garganta\".\n",
    "- En el estado \"COVID-19\", tiene un 30% de probabilidad de observar \"tos\", un 50% de observar \"fiebre\", y un 20% de observar \"dolor de garganta\".\n",
    "\n",
    "## 4. **True Hidden States (Estados Ocultos Verdaderos)**\n",
    "\n",
    "En el contexto de un modelo de cadenas de Markov ocultas (HMM), los **true hidden states** o **estados ocultos verdaderos** son los estados subyacentes que el modelo trata de inferir, pero que no son observables directamente. Estos estados subyacentes son esenciales para comprender el comportamiento del sistema, pero no pueden ser observados de manera directa desde el exterior.\n",
    "\n",
    "### Propósito de los true hidden states:\n",
    "- **Inferencia de estados**: Aunque no podemos observar directamente los estados ocultos verdaderos, el objetivo del modelo es estimarlos a partir de las observaciones disponibles. Estos estados representan, por ejemplo, la condición real de un paciente (como estar en estado de \"Resfriado\", \"Gripe\" o \"COVID-19\"), mientras que las observaciones son síntomas como \"tos\", \"fiebre\" y \"dolor de garganta\".\n",
    "- **Propósito del modelo**: El modelo de Markov oculto se utiliza para inferir cuál es la secuencia más probable de estos estados ocultos dados las observaciones, utilizando algoritmos como el **algoritmo de Viterbi** para la inferencia de la secuencia de estados más probable.\n",
    "\n",
    "### Ejemplo:\n",
    "En un modelo HMM para el diagnóstico de enfermedades, los true hidden states podrían ser los diagnósticos reales (\"Resfriado\", \"Gripe\", \"COVID-19\"), pero solo podemos observar los síntomas (como \"tos\", \"fiebre\", \"dolor de garganta\"). El objetivo del modelo es inferir, con base en los síntomas observados, cuál es la enfermedad subyacente.\n",
    "\n",
    "### ¿Cómo se infieren los true hidden states?\n",
    "Aunque no se pueden observar directamente, se pueden estimar usando las probabilidades de transición entre estados (A), las probabilidades de emisión de observaciones (B) y las distribuciones iniciales de los estados (π). Algoritmos como el **algoritmo de Viterbi** (para la secuencia más probable) o el **algoritmo de filtro hacia atrás** se utilizan para inferir estos estados ocultos verdaderos de forma probabilística.\n",
    "\n",
    "# Algoritmo de Forward en HMM\n",
    "\n",
    "Para encontrar el vector de probabilidades dado una secuencia de observaciones en un modelo de **Markov oculto (HMM)**, puedes usar el **algoritmo de Forward**. Este algoritmo te permite calcular la probabilidad de observar una secuencia de observaciones específica, dado un modelo HMM con parámetros de transición, emisión y distribución inicial (π).\n",
    "\n",
    "## 1. Cálculo de la probabilidad en cada estado\n",
    "\n",
    "Dado un HMM con parámetros:\n",
    "\n",
    "- **π**: El vector de probabilidades iniciales (distribución de los estados en el primer tiempo).\n",
    "- **A**: La matriz de transición de estados.\n",
    "- **B**: La matriz de emisión de observaciones.\n",
    "\n",
    "El algoritmo **Forward** calcula la probabilidad de observar la secuencia de observaciones $O = [o_1, o_2, \\dots, o_T]$ hasta el tiempo $T$, en cada estado del modelo. La idea es calcular $\\alpha_t(i)$, que representa la probabilidad de estar en el estado $i$ en el tiempo $t$, dado que se ha observado la secuencia hasta ese punto.\n",
    "\n",
    "## 2. **Cálculo del vector de probabilidades dado una secuencia**\n",
    "\n",
    "El algoritmo de **Forward** se puede dividir en tres partes:\n",
    "\n",
    "### Inicialización\n",
    "\n",
    "Se inicializa el primer tiempo $t = 0$ usando la distribución inicial y las probabilidades de emisión de la observación:\n",
    "\n",
    "$$\n",
    "\\alpha_0(i) = \\pi_i \\cdot B_{i, o_1}\n",
    "$$\n",
    "\n",
    "Donde $B_{i, o_1}$ es la probabilidad de observar $o_1$ dado el estado $i$.\n",
    "\n",
    "### Recursión\n",
    "\n",
    "Para cada tiempo $t$ de la secuencia, calculamos la probabilidad de estar en el estado $i$ en el tiempo $t$, dado todas las observaciones previas:\n",
    "\n",
    "$$\n",
    "\\alpha_t(i) = \\sum_j \\alpha_{t-1}(j) \\cdot A_{ji} \\cdot B_{i, o_t}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- $\\alpha_{t-1}(j)$ es la probabilidad de estar en el estado $j$ en el tiempo $t-1$.\n",
    "- $A_{ji}$ es la probabilidad de transición de estado de $j$ a $i$.\n",
    "- $B_{i, o_t}$ es la probabilidad de observar $o_t$ dado que estamos en el estado $i$.\n",
    "\n",
    "### Terminación\n",
    "\n",
    "La probabilidad de la secuencia completa es la suma de las probabilidades de estar en cualquier estado en el último tiempo $T$:\n",
    "\n",
    "$$\n",
    "P(O | \\lambda) = \\sum_i \\alpha_T(i)\n",
    "$$\n",
    "\n",
    "Esta es la probabilidad total de observar la secuencia $O$ dada la secuencia de observaciones.\n",
    "\n",
    "## Resumen\n",
    "\n",
    "En un **Modelo Oculto de Markov (HMM)**, los tres componentes clave son:\n",
    "\n",
    "- **π (Distribución inicial)**: Establece las probabilidades de que el sistema comience en cada uno de los estados ocultos.\n",
    "- **A (Matriz de transición)**: Describe las probabilidades de transición entre los estados ocultos de un paso temporal al siguiente.\n",
    "- **B (Matriz de emisión)**: Define las probabilidades de observar ciertos eventos o salidas dadas las transiciones entre los estados ocultos.\n",
    "- **True Hidden States (Estados Ocultos Verdaderos)**: Son los estados subyacentes que no se observan directamente, pero que se infieren utilizando las observaciones y el modelo HMM.\n",
    "\n",
    "Estos tres componentes son esenciales para modelar un HMM y permitir tareas como:\n",
    "- Inferir los estados ocultos dados un conjunto de observaciones.\n",
    "- Predecir observaciones futuras a partir de un modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Add the parent directory to the system path to allow importing from modules located there\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "# Import necessary libraries\n",
    "from likelihood.models.hmm import HMM\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 90:\n",
      "Pi: [0.24996993 0.24966814 0.24975448 0.25060746]\n",
      "A:\n",
      "[[0.41779082 0.47506256 0.08063185 0.02651477]\n",
      " [0.43302362 0.20388675 0.34632147 0.01676815]\n",
      " [0.05776522 0.26247905 0.591388   0.08836772]\n",
      " [0.10993781 0.47557343 0.4036911  0.01079767]]\n",
      "B:\n",
      "[[0.53740562 0.46259438 0.        ]\n",
      " [0.54518243 0.45481757 0.        ]\n",
      " [0.5433659  0.4566341  0.        ]\n",
      " [0.52223023 0.47776977 0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding Accuracy: 20.00%\n",
      "Best configuration: (3, 2, 100) with accuracy 66.67%\n"
     ]
    }
   ],
   "source": [
    "# Define the HMM class (the one we just created)\n",
    "# If you haven't already, make sure to define the HMM class with the methods we discussed.\n",
    "\n",
    "# Define the parameters of the model\n",
    "n_states = 3  # Sunny (0), Rainy (1), Cloudy (2)\n",
    "n_observations = 2  # Walk (0), Shop (1)\n",
    "\n",
    "# Create an HMM instance\n",
    "hmm = HMM(n_states, n_observations)\n",
    "\n",
    "# Generate some synthetic observation sequences (e.g., 3 sequences of 5 days)\n",
    "# Each number represents an observation: 0 -> Walk, 1 -> Shop\n",
    "sequences = [\n",
    "    [0, 1, 0, 0, 1],  # Sequence 1: Walk, Shop, Walk, Walk, Shop\n",
    "    [1, 1, 0, 1, 0],  # Sequence 2: Shop, Shop, Walk, Shop, Walk\n",
    "    [0, 0, 0, 1, 1],  # Sequence 3: Walk, Walk, Walk, Shop, Shop\n",
    "]\n",
    "\n",
    "# Define the true hidden states for the sequences (ground truth for training/testing)\n",
    "true_states = [\n",
    "    [0, 0, 0, 1, 2],  # Sequence 1: Sunny, Sunny, Sunny, Rainy, Cloudy\n",
    "    [1, 1, 0, 1, 2],  # Sequence 2: Rainy, Rainy, Sunny, Rainy, Cloudy\n",
    "    [0, 0, 0, 1, 2],  # Sequence 3: Sunny, Sunny, Sunny, Rainy, Cloudy\n",
    "]\n",
    "\n",
    "# Test various model configurations\n",
    "state_configs = [2, 3, 4]\n",
    "observation_configs = [2, 3]\n",
    "iterations_configs = [20, 50, 100]\n",
    "best_accuracy = 0\n",
    "best_config = None\n",
    "\n",
    "for n_states in state_configs:\n",
    "    for n_observations in observation_configs:\n",
    "        for n_iter in iterations_configs:\n",
    "            hmm = HMM(n_states, n_observations)\n",
    "            print(\n",
    "                f\"Training HMM with {n_states} states, {n_observations} observations, {n_iter} iterations...\"\n",
    "            )\n",
    "            hmm.baum_welch(sequences, n_iterations=n_iter)\n",
    "            accuracy = hmm.decoding_accuracy(sequences, true_states)\n",
    "            print(f\"Decoding Accuracy: {accuracy:.2f}%\")\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_config = (n_states, n_observations, n_iter)\n",
    "                hmm.save_model()\n",
    "\n",
    "print(f\"Best configuration: {best_config} with accuracy {best_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding Accuracy (model rebuilt): 66.67%\n",
      "Test Sequence: [0, 1, 0, 0, 1]\n",
      "Predicted States: [1 2 0 1 2]\n",
      "Probabilities States: [[0.28881071 0.29983091 0.41135838]\n",
      " [0.39043702 0.4413433  0.16821968]\n",
      " [0.205372   0.41355892 0.38106908]\n",
      " [0.20307488 0.42611921 0.37080591]\n",
      " [0.32762052 0.43253756 0.23984192]]\n",
      "Total probability: [0.28306303 0.40267798 0.31425899]\n"
     ]
    }
   ],
   "source": [
    "hmm = HMM(n_states, n_observations)\n",
    "hmm = hmm.load_model()\n",
    "accuracy = hmm.decoding_accuracy(sequences, true_states)\n",
    "print(f\"Decoding Accuracy (model rebuilt): {accuracy:.2f}%\")\n",
    "test_sequence = [0, 1, 0, 0, 1]  # Test sequence: Walk, Shop, Walk, Walk, Shop\n",
    "predicted_states = hmm.viterbi(test_sequence)\n",
    "smoothed_probs = hmm.state_probabilities(test_sequence)\n",
    "total_prob = hmm.sequence_probability(test_sequence)\n",
    "\n",
    "print(f\"Test Sequence: {test_sequence}\")\n",
    "print(f\"Predicted States: {predicted_states}\")\n",
    "print(f\"Probabilities States: {smoothed_probs}\")\n",
    "print(f\"Total probability: {total_prob}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
